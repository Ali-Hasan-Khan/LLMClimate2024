tokenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26.0/26.0 [00:00<00:00, 769B/s]
config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 665/665 [00:00<00:00, 26.6kB/s]
vocab.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.04M/1.04M [00:00<00:00, 2.24MB/s]
merges.txt: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 1.32MB/s]
tokenizer.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.36M/1.36M [00:00<00:00, 2.87MB/s]






















































model.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 548M/548M [06:03<00:00, 1.51MB/s]
generation_config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 124/124 [00:00<00:00, 5.66kB/s]
Generating test split: 140 examples [00:02, 64.61 examples/s]
config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 631/631 [00:00<00:00, 30.8kB/s]
tokenizer_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.89k/1.89k [00:00<00:00, 809kB/s]
spiece.model: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 792k/792k [00:00<00:00, 2.32MB/s]
tokenizer.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.42M/2.42M [00:00<00:00, 4.64MB/s]
special_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.79k/1.79k [00:00<00:00, 764kB/s]













































































































































































































































































































pytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.13G/3.13G [36:04<00:00, 1.45MB/s]
  0%|                                                                                                                                                                             | 0/140 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "./summary_evaluation.py", line 292, in <module>
    args = parser.parse_args(sys.argv[1:])
  File "./summary_evaluation.py", line 186, in main
  File "/app/tools.py", line 99, in summarise_question
    encodeds = tokenizer.apply_chat_template(messages, return_tensors="pt")
AttributeError: 'GPT2TokenizerFast' object has no attribute 'apply_chat_template'
Traceback (most recent call last):
  File "./summary_evaluation.py", line 292, in <module>
    args = parser.parse_args(sys.argv[1:])
  File "./summary_evaluation.py", line 186, in main
  File "/app/tools.py", line 99, in summarise_question
    encodeds = tokenizer.apply_chat_template(messages, return_tensors="pt")
AttributeError: 'GPT2TokenizerFast' object has no attribute 'apply_chat_template'